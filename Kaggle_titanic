###########################################
#kaggle comp
#titantic
#practice
###########################################


fileLoc = c("D:/cj/book/titanic")

#read in data

gender = read.csv(paste(fileLoc, "/gender_submission.csv", sep=""))

train = read.csv(paste(fileLoc, "/train.csv", sep=""))

test = read.csv(paste(fileLoc, "/test.csv", sep=""))


###########################################
#logistic regression test begin
###########################################
#missing 
sapply(train,function(x) sum(is.na(x)))

#n of unique var
sapply(train, function(x) length(unique(x)))

#plot missing
library(Amelia)
missmap(train, main = "Missing values vs observed")


#fill missing
#MICE
library(mice)

#pattern
md.pattern(train)


#delete useless column
#trainPrep = subset(train, select = -c(Cabin))
init = mice(trainPrep, maxit=0)
meth = init$method
predM = init$predictorMatrix
predM[, c("Age", "PassengerId", "Survived", "Name","Ticket")]=0 # will remove Age as a predictor but still will be imputed

#build method table
meth[c("SibSp", "Parch", "Fare")] = "pmm"
meth[c("Sex")] = "logreg"
meth[c("Pclass")] = "Proportional odds model"
meth[c("Embarked")] = "polyreg"


#impute
set.seed(123)

imputeTrain = mice(trainPrep, method=meth, predictorMatrix=predM, m=5)

#check imputed num
imputeTrain$imp$Age

#fill the missing with the 3rd imputation
imputeTrain = complete(imputeTrain, 3)

# imputeTrain$Cabin = train$Cabin
imputeTrain = subset(imputeTrain, select = -c(Cabin, Name, PassengerId, Ticket))



#logistic regression begin
model <- glm(Survived ~., family = binomial(link = 'logit'), data = imputeTrain)
summary(model)

# 
# model2 <- glm(Survived ~., family = quasibinomial, data = imputeTrain)
# summary(model2)

# run the anova() function on the model to analyze the table of deviance

anova(model, test="Chisq")
# anova(model2, test="Chisq")


#test for stepwise var selection
library(MASS)
step.model <- model %>% stepAIC(trace = FALSE)
coef(step.model)

#test for some theories


#theory, sibsp and parch will affect survival rate

#test for age: category
imputeTrain$ageCat <- cut(imputeTrain$Age, c(0,10,20,30,40,50,60), labels=c(1:6))

imputeTrain$ageCat = as.factor(imputeTrain$ageCat)

test <- glm(Survived ~Pclass + Sex + ageCat + SibSp, family = binomial(link="logit"), data = imputeTrain)
summary(test)

test2 <- glm(Survived ~Pclass + ageCat*Embarked + Sex + ageCat + SibSp, family = binomial(link="logit"), data = imputeTrain)

summary(test2)

#theory approved, different age group act differently on sibsp and parch

#theory: age and embark has some interaction
#theory approved


#theory: fare has some significant part if with decent transformation
summary(imputeTrain$Survived[imputeTrain$Fare>=31])
summary(imputeTrain$Survived[imputeTrain$Fare<=10])
#58% vs 20%, something here
#theory approved


#transform age to categorical var
#transform fare to categorical var
#add all lv-one interaction
#stepwise regression
library(dplyr)

imputeTrain2 = imputeTrain %>% 
  mutate(age10 = ifelse(Age %in% c(0,9),1,0), age20 = ifelse(Age %in% c(10,19),1,0),
         age30 = ifelse(Age %in% c(20,29),1,0), age40 = ifelse(Age %in% c(30,39),1,0),
         age50 = ifelse(Age %in% c(40,49),1,0), age60 = ifelse(Age %in% c(50,59),1,0),
         age60plus = ifelse(Age >= 60,1,0), fareTop = ifelse(Fare >= quantile(Fare,.75),1,0),
         fareBottom = ifelse(Fare <= quantile(Fare,.25),1,0) )

imputeTrain2 = subset(imputeTrain2, select = -c(ageCat))


#data done, now add all interactions lv1

model2 <- glm(Survived ~., family = binomial(link = 'logit'), data = imputeTrain2)
summary(model2)

#k = qchisq(p, 1, lower.tail = F), For instance, for p = 0.05, set k = 3.8415.

step(model2, scope = . ~ .^2, direction = "forward", k = 3.8415)


# last result
#this is the lowest aic model

modelFinal <- glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + 
                    Fare + Embarked + age10 + age20 + age30 + age40 + age50 + 
                    age60 + age60plus + fareTop + fareBottom + Pclass:Sex + Sex:fareBottom + 
                    Embarked:age30 + Age:Parch + Age:SibSp + Sex:age10, family = binomial(link = "logit"), 
                  data = imputeTrain2)

summary(modelFinal) #AIC: 757.19


#only keep significant ones
modelFinal2 <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + 
                     age10 + fareBottom + Pclass:Sex + Sex:fareBottom + 
                     Embarked:age30 + Age:Parch + Age:SibSp + Sex:age10,
                   family = binomial(link = "logit"), data = imputeTrain2)

summary(modelFinal2) #AIC: 746.16


fitted.results <- predict(modelFinal2, imputeTrain2,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != imputeTrain2$Survived)
print(paste('Accuracy',1-misClasificError)) #0.823793490460157


###########################################################
#test in test data
#fill in missing

#pattern
md.pattern(test)


#delete useless column
#trainPrep = subset(train, select = -c(Cabin))
init = mice(test, maxit=0)
meth = init$method
predM = init$predictorMatrix
predM[, c("Age", "PassengerId", "Name","Ticket", "Fare")]=0 # will remove Age as a predictor but still will be imputed

#build method table
meth[c("SibSp", "Parch", "Fare", "Age")] = "pmm"
meth[c("Sex")] = "logreg"
meth[c("Pclass")] = "Proportional odds model"
meth[c("Embarked")] = "polyreg"


#impute
set.seed(123)

imputeTest = mice(test, method=meth, predictorMatrix=predM, m=5)

#check imputed num
imputeTest$imp$Age

#fill the missing with the 3rd imputation
imputeTest = complete(imputeTest, 3)

# imputeTrain$Cabin = train$Cabin
imputeTest = subset(imputeTest, select = -c(Cabin, Name, PassengerId, Ticket))


imputeTest2 = imputeTest %>%
  mutate(age10 = ifelse(Age %in% c(0,9),1,0), age20 = ifelse(Age %in% c(10,19),1,0),
         age30 = ifelse(Age %in% c(20,29),1,0), age40 = ifelse(Age %in% c(30,39),1,0),
         age50 = ifelse(Age %in% c(40,49),1,0), age60 = ifelse(Age %in% c(50,59),1,0),
         age60plus = ifelse(Age >= 60,1,0), fareTop = ifelse(Fare >= 31,1,0),
         fareBottom = ifelse(Fare <= 7.9104,1,0) )


fitted.results2 <- predict(modelFinal2, imputeTest2,type='response')
fitted.results2 <- ifelse(fitted.results2 > 0.5,1,0)
misClasificError <- mean(fitted.results2 != gender$Survived)
print(paste('Accuracy',1-misClasificError)) #0.925837320574163
##########################################################################################

#another method for subseting
#LASSO
library(glmnet)

xTrain <- data.matrix(imputeTrain2[,2:17])
yTrain <- data.matrix(imputeTrain2[,1])

modLasso <- glmnet( xTrain, imputeTrain2[,1],
                   alpha=1, nlambda=100, lambda.min.ratio=0.0001,family="binomial")

modCV <- cv.glmnet(xTrain, imputeTrain2[,1], alpha=1,family="binomial", 
                   nlambda=100, type.measure = "class")


plot(modCV)
best.lambda <- modCV$lambda.min
best.lambda
co <- coef(modCV, s = "lambda.min")

p <- predict(modLasso, s=best.lambda, type="coefficients") [1:10,]

#predict output values based on selected predictors
p <- predict(modCV, s=best.lambda, newx=xTrain,type="class")
# Calculate accuracy
Accuracy <- mean(p==yTrain) #0.8024691

#predict output values based on selected predictors
#predict test data
p <- predict(modCV, s=best.lambda, newx=data.matrix(imputeTest2), type="class")
# Calculate accuracy
Accuracy <- mean(p==gender$Survived) #0.9497608


##################################################################
#####################not working so well
#####################test data could missing some major categories
##################################################################
#trying to add all interaction before lasso step
# First step: using .*. for all interactions
f <- as.formula(Survived ~ .*.)
# yTrain <- data.matrix(imputeTrain2[,1])
xTrain2 <- model.matrix(f, imputeTrain2)


modLasso2 <- glmnet( xTrain2, imputeTrain2[,1],
                    alpha=1, nlambda=100, lambda.min.ratio=0.0001,family="binomial")

modCV2 <- cv.glmnet(xTrain2, imputeTrain2[,1], alpha=1,family="binomial", 
                   nlambda=100, type.measure = "class")


plot(modCV2)
best.lambda <- modCV2$lambda.min
best.lambda
co <- coef(modCV2, s = "lambda.min")

p <- predict(modLasso2, s=best.lambda, type="coefficients") [1:10,]

#predict output values based on selected predictors
p <- predict(modCV2, s=best.lambda, newx=xTrain2, type="class")
# Calculate accuracy
Accuracy <- mean(p==yTrain) #0.8361392


#predict output values based on selected predictors
#predict test data
imputeTest3 = cbind.data.frame(gender$Survived, imputeTest2)
colnames(imputeTest3)[1]="Survived"


# imputeTest4 <- rbind.data.frame(imputeTest3, rep(NA, 17))
# imputeTest4[419,"Embarked"] <-

xTest <- model.matrix(f, imputeTest3)

#fill the missing category
# addOn <- matrix(NA, 418, 16)
addOn <- matrix(0, 418, 16)
colnames(addOn) <- colnames(xTrain2)[!(colnames(xTrain2) %in% colnames(xTest))]

xTest2 <- cbind.data.frame(xTest, addOn)


p <- predict(modCV2, s=best.lambda, newx=data.matrix(xTest2), type="class")
# Calculate accuracy
Accuracy <- mean(p==gender$Survived) #0.6315789
##################################################################
#####################not working so well sign end
##################################################################




#####################################
#KNN test begin

#normalization data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) }

imputeTrain3 <- as.data.frame(lapply(imputeTrain2[,c(4,7)], normalize))
colnames(imputeTrain3) <- c("ageNorm", "fareNorm")
imputeTrain3 <- cbind.data.frame(imputeTrain2, imputeTrain3)


#cabin might affect?
#missing going to bottom level
#define cabine to A-F, missing going to G
cabin <- cbind.data.frame(train$Cabin, rep("", nrow(train)))
colnames(cabin) <- c("Cabin", "cabinCat")
cabin[] <- lapply(cabin, as.character)

for(i in 1:nrow(cabin)){
  cabin$cabinCat[i] <- ifelse(grepl("A", cabin$Cabin[i]), "A",
                          ifelse(grepl("B", cabin$Cabin[i]), "B",
                                 ifelse(grepl("C", cabin$Cabin[i]), "C",
                                        ifelse(grepl("D", cabin$Cabin[i]), "D",
                                               ifelse(grepl("E", cabin$Cabin[i]), "E",
                                                      ifelse(grepl("F", cabin$Cabin[i]), "F",
                                                             ifelse(grepl("G", cabin$Cabin[i]), "G",
                                                                    ifelse(cabin$Cabin[i]=="", "H",cabin$Cabin[i]))))))))
}


imputeTrain3 <- cbind.data.frame(imputeTrain3, cabin$cabinCat)
colnames(imputeTrain3)[ncol(imputeTrain3)] <- "cabinCat"

#pct by cabin cat
imputeTrain3 %>% group_by(cabinCat) %>% summarise(proc = sum(Survived)/n(), minFare = min(Fare))


#transform all categorical var to dummy var
imputeTrain3 <- imputeTrain3 %>% 
  mutate(cabinCatB = ifelse(cabinCat =="B",1,0), cabinCatC = ifelse(cabinCat =="C",1,0),
         cabinCatD = ifelse(cabinCat =="D",1,0), cabinCatE = ifelse(cabinCat =="E",1,0),
         cabinCatF = ifelse(cabinCat =="F",1,0), cabinCatG = ifelse(cabinCat =="G",1,0),
         cabinCatH = ifelse(cabinCat =="H",1,0), cabinCatA = ifelse(cabinCat =="A",1,0),
         EmbarkedC = ifelse(Embarked =="C",1,0), EmbarkedQ = ifelse(Embarked =="Q",1,0),
         EmbarkedS = ifelse(Embarked =="S",1,0) )



############
#re run logistics regression


 

model2 <- glm(Survived ~., family = binomial(link = 'logit'), data = imputeTrain3)
summary(model2)

#k = qchisq(p, 1, lower.tail = F), For instance, for p = 0.05, set k = 3.8415.

step(model2, scope = . ~ .^2, direction = "forward", k = 3.8415)


model2Final <- glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + 
                     Fare + Embarked + age10 + age20 + age30 + age40 + age50 + 
                     age60 + age60plus + fareTop + fareBottom + ageNorm + fareNorm + 
                     cabinCat + cabinCatB + cabinCatC + cabinCatD + cabinCatE + 
                     cabinCatF + cabinCatG + cabinCatH + cabinCatA + EmbarkedC + 
                     EmbarkedQ + EmbarkedS + Pclass:Sex + Sex:fareBottom + Age:cabinCatE + 
                     age30:EmbarkedS + Sex:cabinCatC + Age:Parch + age60:cabinCatC + 
                     SibSp:cabinCatB + Parch:cabinCatC + Sex:ageNorm + Parch:EmbarkedQ + 
                     SibSp:EmbarkedS + Sex:EmbarkedQ + Fare:cabinCatG + Pclass:fareTop + 
                     SibSp:ageNorm + age40:cabinCatH + Sex:age10 + SibSp:cabinCatD, 
                   family = binomial(link = "logit"), data = imputeTrain3)


summary(model2Final) #AIC: 722.98


#only keep significant ones
#only keep variables that make means
model2Final2 <- glm(formula = Survived ~ Pclass + Sex + Parch + 
                      age10 + age20 + age30 + age40 +  age60 +
                      age60plus + fareTop + fareNorm + Pclass:Sex + Sex:fareBottom + Age:cabinCatE + 
                      age30:EmbarkedS + Sex:cabinCatC + Age:Parch +  
                      SibSp:cabinCatB + Parch:cabinCatC + Sex:ageNorm + 
                      SibSp:EmbarkedS + Sex:EmbarkedQ + Pclass:fareTop + 
                      SibSp:ageNorm + age40:cabinCatH + Sex:age10 + SibSp:cabinCatD, 
                    family = binomial(link = "logit"), data = imputeTrain3)


summary(model2Final2) #AIC: 725.03


fitted.results <- predict(model2Final2, imputeTrain3,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != imputeTrain3$Survived)
print(paste('Accuracy',1-misClasificError)) #0.851851851851852

#######
#######
#apply it on test data

cabinT <- cbind.data.frame(test$Cabin, rep("", nrow(test)))
colnames(cabinT) <- c("Cabin", "cabinCat")
cabinT[] <- lapply(cabinT, as.character)

for(i in 1:nrow(cabinT)){
  cabinT$cabinCat[i] <- ifelse(grepl("A", cabinT$Cabin[i]), "A",
                              ifelse(grepl("B", cabinT$Cabin[i]), "B",
                                     ifelse(grepl("C", cabinT$Cabin[i]), "C",
                                            ifelse(grepl("D", cabinT$Cabin[i]), "D",
                                                   ifelse(grepl("E", cabinT$Cabin[i]), "E",
                                                          ifelse(grepl("F", cabinT$Cabin[i]), "F",
                                                                 ifelse(grepl("G", cabinT$Cabin[i]), "G",
                                                                        ifelse(cabinT$Cabin[i]=="", "H",cabinT$Cabin[i]))))))))
}

imputeTest4 <- na.omit(imputeTest4)


imputeTest5 <- as.data.frame(lapply(imputeTest4[,c(4,7)], normalize))
colnames(imputeTest5) <- c("ageNorm", "fareNorm")
imputeTest5 <- cbind.data.frame(imputeTest4, imputeTest5)


imputeTest5 <- cbind.data.frame(imputeTest5, cabinT$cabinCat)
colnames(imputeTest5)[ncol(imputeTest5)] <- "cabinCat"

imputeTest5 = imputeTest5 %>%
  mutate(cabinCatB = ifelse(cabinCat =="B",1,0), cabinCatC = ifelse(cabinCat =="C",1,0),
         cabinCatD = ifelse(cabinCat =="D",1,0), cabinCatE = ifelse(cabinCat =="E",1,0),
         cabinCatF = ifelse(cabinCat =="F",1,0), cabinCatG = ifelse(cabinCat =="G",1,0),
         cabinCatH = ifelse(cabinCat =="H",1,0), cabinCatA = ifelse(cabinCat =="A",1,0),
         EmbarkedC = ifelse(Embarked =="C",1,0), EmbarkedQ = ifelse(Embarked =="Q",1,0),
         EmbarkedS = ifelse(Embarked =="S",1,0) )





fitted.results2 <- predict(model2Final2, imputeTest5,type='response')
fitted.results2 <- ifelse(fitted.results2 > 0.5,1,0)
misClasificError <- mean(fitted.results2 != gender$Survived)
print(paste('Accuracy',1-misClasificError)) #0.870813397129187

######################################################################################
######################################################################################
######################################################################################

#what would be the actual data?
#build an comparison dataset based on score difference
actualResult <- gender
actualResult$best <- fitted.results2
actualResult$bestSum <- ifelse(actualResult$best != actualResult$Survived, actualResult$best, "")

actualResult$current <- fitted.results2
